Pada kesempatan kali ini, saya akan mendokumentasikan bagaimana cara instalasi java 11 openjdk, zookeeper dan kafka ke dalam WSL yang telah di install dalam materi sebelumnya (CentOS 8).
# A. Instalasi Java
langkah pertama yaitu memeriksa update yang ada dengan menggunakan perintah 
```
sudo yum update -y
```
selanjutnya masuk ke install java 11 dengan perintah:
```
sudo yum install -y java-11-openjdk-devel
```
tunggu sampai selesai, setelah selesai maka dapat di cek dengan perintah:
```
java -version
```
# B. Instalasi Zookeeper dan Java
1. terdapat beberapa cara dalam melakukan instalasi keduanya, sebelumnya saya telah mencoba untuk menginstall masing-masing namun tidak berhasil, jadi saya menginstallnya secara sekaligus dengan menggunakan kafka quickstart yang dimulai dengan mengunduh di situs wen kafka berikut: 
https://kafka.apache.org/quickstart
2. pilih kafka dengan versi terbaru yang sudah rilis kemudian copy link nya
 ![image](https://github.com/ferdyansahalfariz/belajar-linux/assets/96871156/856c75a0-6a42-4086-8321-09d2136f0a09)
3. buka centOS dan buat perintah:
```
wget https://dlcdn.apache.org/kafka/3.7.0/kafka_2.13-3.7.0.tgz
```
4. extract filenya
```
tar -xvzf kafka_2.13-3.7.0.tgz
```
5. pindahkan ke folder /opt/
```
mv kafka_2.13-3.7.0/opt/
```
# C. Running zookeeper dan kafka
untuk running, dimulai dengan zookeeper terlebih dahulu dengan perintah 
```
bin/zookeeper-server-start.sh config/zookeeper.properties
```
dengan tampilan seperti berikut:
![Screenshot (9)](https://github.com/ferdyansahalfariz/belajar-linux/assets/96871156/7ba99116-c700-4195-a3e5-5de9b4633b82)
kemudian tanpa menutup atau memberhentikan service yang berjalan di zookeeper, lakukan running untuk kafkanya dengan perintah
```
bin/kafka-server-start.sh config/server.properties
```
# D. Konfigurasi menggunakan Systemd
Pada kenyataannya, saya tidak dapat menjalankan kafka dengan cara diatas, jadi sebagai cara lainnya, saya menggunakan systemd yang dapat menjalankan kedua service tersebut secara bersamaan. terdapat beberapa konfigurasi yang dilakukan sebelumnya.
1. pastikan bahwa sudah terdapat systemd pada wsl di dalam wsl.conf dengan melakukan perintah :
```
sudo vim /etc/wsl.conf
```
jika dalam file tersebut belum ada maka tambahkan isian berikut dengan tombol 'i' untuk insert kemudian tambahkan:
```
[network]
generateHosts = false

#mount with options
[automount]
options = "metadata"

[boot]
systemd=true
```
setelah selesai, tekan ESC untuk keluar menu insert dan ':wq' untuk simpan dan keluar. selanjutnya lakukan perintah
```
wsl.exe --shutdown 
```
dari PowerShell untuk memulai ulang instans WSL. Setelah distribusi dimulai ulang, systemd harus berjalan. Ddapat mengonfirmasi menggunakan perintah :
```
systemctl list-unit-files --type=service
```
, yang akan menampilkan status layanan yang ada.

2. setelahnya maka jalankan perintah
```
sudo nvim /etc/systemd/system/zookeeper.service
```
untuk membuat file baru zookeeper.service dan masukan
```
[Unit]
Description=Apache zookeeper
Documentation=https://zookeeper.apache.org/
Requires=network.target remote-fs.target
After=network.target remote-fs.target

[Service]
Type=simple
User=root
ExecStart=/opt/kafka_2.13-3.7.0/bin/zookeeper-server-start.sh /opt/kafka_2.13-3.7.0/config/zookeeper.properties
ExecStop=/opt/kafka_2.13-3.7.0/bin/zookeeper-server-stop.sh
Restart=on-abnormal

[Install]
WantedBy=multi-user.target
```
pastikan user yang digunakan sesuai yang akan jalankan servicenya, dan sesuaikan juga dengan lokasi direktori tempat menyimpan file nya.

3. selanjutnya yaitu melakukan konfigurasi yang sama dimulai dengan membuat perintah
```
sudo nvim /etc/systemd/system/kafka.service
```
4.  untuk membuat file kafka.service dan lakukan insert dengan isi:
```
[Unit]
Description=Apache zookeeper
Documentation=https://zookeeper.apache.org/
Requires=network.target remote-fs.target
After=network.target remote-fs.target

[Service]
Type=simple
User=root
ExecStart=/opt/kafka_2.13-3.7.0/bin/zookeeper-server-start.sh /opt/kafka_2.13-3.7.0/config/zookeeper.properties
ExecStop=/opt/kafka_2.13-3.7.0/bin/zookeeper-server-stop.sh
Restart=on-abnormal

[Install]
WantedBy=multi-user.target
```
5. setelah kedua service sudah dibuat, maka dapat langsung menjalankan perintah kepada kafka.service menggunakan systemd dengan command:
```
sudo systemctl enable --now kafka.service
```
seharusnya kedua service baik zookeeper dan kafka sudah berjalan. untuk melakukan pengecekan statusnya, gunakan perintah 
```
systemctl status kafka
```
yang akan menunjukan status active(running) pada service kafka.
![Screenshot (10)](https://github.com/ferdyansahalfariz/belajar-linux/assets/96871156/7415dc6a-d120-4400-ae6a-9f681b6cfe1f)

# 5 Juni 2024
# Pengertian Kafka
sebelum lebih jauh belajar tentang kafka, alangkah baiknya mengetahui apa definisi kafka dan apa yang ada di dalamnya termasuk topic, broker, offset, cunsumer group dan lain sebagainya.

# Kafka
kafka merupakan suatu sistem yang di rancang sebagai publish/subscribe messaging system, artinya kafka adalah platform streaming terdistribusi yang digunakan dalam pembuatan aplikasi data streaming secara real time. kafka dapat menghandle data streaming dalam jumlah yang banyak kemudian diolah untuk mengirim dan menerima pesan dalam waktu nyata

Apache Kafka adalah platform streaming terdistribusi yang digunakan untuk membangun aplikasi data real-time. Kafka awalnya dikembangkan oleh LinkedIn dan kemudian menjadi proyek open source yang disponsori oleh Apache Software Foundation. Kafka dirancang untuk menangani data streaming dengan volume tinggi dan menyediakan mekanisme yang handal untuk mengirim dan menerima pesan dalam waktu nyata. Adapun kafka terdiri dari beberapa komponen utama, yaitu producer, broker, topic, dan consumer.

Kafka sangat berguna untuk membangun aplikasi yang membutuhkan pengolahan data real-time, seperti monitoring log, analisis data streaming, dan integrasi data antara sistem yang berbeda. Dengan Kafka, aplikasi dapat mengelola dan memproses aliran data besar dengan latensi rendah dan throughput tinggi.

# Topic
Topic sendiri adalah kategori atau saluran tempat pesan dikirimkan. Dalam Kafka, setiap pesan yang diproduksi oleh producer dikaitkan dengan sebuah topic. Topic di Kafka bersifat multi-publisher dan multi-subscriber, artinya banyak producer dapat mengirim pesan ke satu topic dan banyak consumer dapat membaca pesan dari satu topic.

# Broker
Broker adalah server Kafka yang bertanggung jawab untuk menyimpan dan mengelola pesan. Kafka cluster terdiri dari satu atau lebih broker. Setiap broker dalam cluster berkomunikasi satu sama lain untuk memastikan distribusi dan replikasi data yang konsisten. Broker juga bertanggung jawab untuk melayani permintaan dari producer dan consumer.

# Cluster
Cluster sendiri merupakan kumpulan broker yang bekerja sama untuk menyediakan layanan streaming data terdistribusi dan tahan lama, memungkinkan pengelolaan data skala besar dengan replikasi, distribusi beban kerja, dan ketersediaan tinggi. Setiap broker menyimpan data dan melayani permintaan dari producer dan consumer, sementara Apache ZooKeeper mengelola metadata cluster dan koordinasi antar broker. Producer mengirim data ke topic yang dibagi menjadi beberapa partition, memungkinkan paralelisme dan replikasi data untuk ketahanan. Consumer membaca data dari broker pemimpin partition, dan ZooKeeper mengelola pemilihan pemimpin saat broker gagal. Cluster Kafka menyediakan ketersediaan tinggi, distribusi beban kerja yang efisien, dan ketahanan terhadap kegagalan, memungkinkan penanganan data real-time dalam skala besar dengan performa dan keandalan tinggi.

![image](https://github.com/ferdyansahalfariz/belajar-linux/assets/96871156/e7516f0a-1216-4542-8408-2fc7ddb80e5a)

# Partition
Partition adalah subdivisi dari sebuah topic di Kafka. Setiap topic dibagi menjadi satu atau lebih partition untuk memungkinkan paralelisme dan skala besar. Partisi adalah unit dasar penyimpanan data di Kafka, dan setiap pesan yang dikirim ke sebuah topic akan disimpan di salah satu partisi topic tersebut.

![image](https://github.com/ferdyansahalfariz/belajar-linux/assets/96871156/f1f5654a-deb6-4e32-89b9-3df878d74a8c)

Karakteristik Partition:

Distribusi Data:
Pesan yang dikirim ke sebuah topic didistribusikan ke beberapa partition berdasarkan key (jika ada) atau secara round-robin jika tidak ada key yang ditentukan.
Setiap partisi disimpan di satu broker dalam cluster, tetapi partisi tersebut dapat direplikasi ke broker lain untuk keandalan dan redundansi.

Skalabilitas:
Dengan membagi topic menjadi beberapa partition, Kafka memungkinkan paralelisme yang tinggi. Producer dapat mengirim pesan ke beberapa partition secara paralel, dan consumer dapat membaca dari beberapa partition secara paralel juga.
Jika beban kerja meningkat, kita dapat menambahkan lebih banyak broker ke cluster dan memindahkan partition untuk mendistribusikan beban lebih merata.

Order (Urutan):
Kafka menjamin urutan pesan hanya dalam level partisi, bukan dalam level topic secara keseluruhan. Ini berarti bahwa pesan-pesan dalam satu partisi akan dikonsumsi dalam urutan yang sama dengan saat dikirim oleh producer, tetapi pesan dari partisi yang berbeda mungkin tidak mengikuti urutan yang sama.

Manfaat Partition:
Pemrosesan Paralel: Dengan memiliki beberapa partition, Kafka memungkinkan consumer group untuk memproses pesan secara paralel, yang meningkatkan throughput dan efisiensi pemrosesan.

Fault Tolerance: Kafka mendukung replikasi partition ke beberapa broker. Jika satu broker gagal, partition yang direplikasi di broker lain akan memastikan data tetap tersedia.

Load Balancing: Dengan mendistribusikan partition di antara beberapa broker, Kafka dapat mendistribusikan beban kerja secara merata dan menghindari bottleneck di satu broker.

Cara Kerja Partition:

Producer: Saat producer mengirimkan pesan ke topic, Kafka menentukan partition mana yang akan menerima pesan tersebut. Jika producer memberikan key, Kafka akan menggunakan hashing pada key untuk menentukan partition. Jika tidak ada key, Kafka akan mendistribusikan pesan secara round-robin.

Consumer: Consumer dalam consumer group akan membaca pesan dari partition yang berbeda. Kafka memastikan bahwa satu partition hanya dibaca oleh satu consumer dalam satu consumer group pada waktu yang sama, yang memastikan pesan diproses sekali dan hanya sekali oleh consumer group tersebut.

Dengan partition, Kafka dapat menangani volume data yang besar dengan efisiensi tinggi, serta memberikan jaminan ketahanan dan distribusi beban yang baik dalam aplikasi real-time.

# Offset
Setiap pesan dalam partisi diberi nomor urut yang disebut offset. Offset ini unik untuk setiap partisi dan digunakan oleh consumer untuk melacak pesan mana yang sudah dibaca dan pesan mana yang belum. Offset merupakan identifikasi unik untuk setiap pesan dalam sebuah partition di sebuah topic. Dengan menggunakan offset, consumer dapat melacak pesan yang sudah dibaca dan pesan yang belum dibaca.

# Consumer Group
Consumer group adalah sekelompok consumer yang bekerja bersama untuk membaca pesan dari satu atau lebih topic. Setiap consumer dalam sebuah consumer group hanya akan membaca sebagian dari pesan yang ada dalam topic, sehingga memungkinkan konsumen untuk membagi beban kerja. Setiap pesan dalam sebuah partition hanya akan dibaca oleh satu consumer dalam consumer group tertentu, sehingga memastikan bahwa setiap pesan hanya diproses sekali dalam satu consumer group.

![image](https://github.com/ferdyansahalfariz/belajar-linux/assets/96871156/42dd44d2-ae08-4b40-bfc2-57a5ca04d314)

# Bagaimana Kafka Bekerja?
Producer: Aplikasi atau layanan yang mengirim pesan ke topic Kafka.
Broker: Menyimpan pesan yang diterima dari producer dan melayani permintaan dari consumer.
Topic: Mengelompokkan pesan yang dikirim oleh producer dan dibaca oleh consumer.
Partition: Setiap topic dibagi menjadi beberapa partition untuk mendistribusikan pesan dan memungkinkan paralelisme.
Consumer: Aplikasi atau layanan yang membaca pesan dari topic Kafka.
Consumer Group: Kumpulan consumer yang berbagi beban kerja untuk membaca pesan dari satu atau lebih topic.
