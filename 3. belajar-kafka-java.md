# 6 juni 2024
## Mengatur routing pada message
pada kesempatan kali ini, melanjutkan dari pengiriman message dari producer ke comsumer, terdapat kondisi dimana message hanya dikirim ke partisi yang sama meskipun sudah diatur bahwa topik tersebut memiliki beberapa partisi. dalam implementasinya menjadikan satu consumer yang berada dalam grup costumer bisa menerima semua messagenya sendirian sementara costumer yang lainnya tidak menerima pesan sama sekali.
untuk menangani hal tersebut, ditambahkan routing untuk mengatur kedalam partisi mana message akan dikirim sehingga tidak hanya disimpan dalam sati partisi yang sama.

Berbeda dengan database dimana terdapat primary key yang bentuknya unik, key dalam kafka dapat sama dan digunakan untuk mengatur dimana partisi yang dipilih. Cara menentukannya yaitu melalui `hash(message.key) % total partisi`. misal dalam contoh dibawah saya membuat topic latihanjava yang mana diatur terdapat 2 partisi. saya menggunakan key "1", maka cara mengolahnya yaitu `hash(1)%2`. jadi dengan key yang sama, maka message akan selalu masuk kedalam partisi yang sama.

Dalam penerapannya, sebenarnya secara default, kafka akan mengatur key pada null/kosong, karena itulah mengapa pada kasus sebelumnya pesan selalu masuk ke 1 consumer saja dikarenakan masuk ke partisi 0 selalu. 

### console Producer
Cara mengatur key dapat menambahkan parameter `--property "parse.key=true" --property "key.separator=:"`

Dari parameter tersebut menunjukan bahwa penggunaan key akan diterapkan dengan pemisah antara key dan messagenya menggunakan tanda `":"`.

### console Consumer
pada bagian consumer, dapat ditambahkan parameter --property "print.key=true" untuk mencetak key yang digunakan guna memvalidasinya nanti.

### praktek
Dimulai dengan mencoba produce data tanpa parameter `--property "parse.key=true" --property "key.separator=:"` dahulu.
```
/opt/kafka_2.13-3.7.0/bin/kafka-console-producer.sh --bootstrap-server localhost:9092 --topic latihanjava
```
![image](https://github.com/ferdyansahalfariz/belajar-linux/assets/96871156/cc79ae9a-127f-4407-ac7c-f0cd8d26bde5)

cek melalui consumer, disini saya menggunakan 3 consumer dalam group yang sama yaitu "belajar" dengan command:
```
/opt/kafka_2.13-3.7.0/bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic latihanjava --group belajar --from-beginning --property "print.key=true"
```
![image](https://github.com/ferdyansahalfariz/belajar-linux/assets/96871156/243e30b6-b9cd-4d70-865a-74e01b4e24c2)

dari pesan tersebut, message hanya terkirim ke 1 customer saja dengan key null

Selanjutnya tambahkan parameter `--property "parse.key=true" --property "key.separator=:"` pada producer dan coba kirim pesan dengan format `"key:message"` seperti berikut:
![image](https://github.com/ferdyansahalfariz/belajar-linux/assets/96871156/7d5f478c-f05a-4af1-a10b-daa899b22fc9)

dapat dilihat pada consumer 1 diterima pesan berikut:
![image](https://github.com/ferdyansahalfariz/belajar-linux/assets/96871156/cf488627-77db-47a3-afec-3606218e808f)

untuk consumer 2 berikut:
![image](https://github.com/ferdyansahalfariz/belajar-linux/assets/96871156/83874adf-b9bd-422d-a120-3bdfdc06b967)

dan consumer 3 tidak menerima message apapun.

Kemudian saya coba untuk stop consumer 1 dan melanjutkan produce data lagi. dapat terlihat bahwa consumer 3 menggantikan consumer 1 untuk menerima message dan message dapat terbagi diantara consumer 2 dan 3 sesuai dengan perbedaan partisi yang ditempati berdasarkan key yang sudah diatur saat message di produce.
![image](https://github.com/ferdyansahalfariz/belajar-linux/assets/96871156/d1c87e43-b3a8-47d9-b2c0-dae4a7ac39ac)


# Membuat Producer dan Consumer dengan java.
1. untuk membuat producer dan consumer dengan java, diperlukan maven sebagai compilernya sehingga menghasilkan hasil akhir berupa jar yang nantinya dapat di run sebagai aplikasi producer dan consumer kafka. pastikan sudah menginstall maven, jika belum maka lakukan perintah berikut:
```
cd /opt
sudo wget https://downloads.apache.org/maven/maven-3/3.8.8/binaries/apache-maven-3.8.8-bin.tar.gz
sudo tar -xvzf apache-maven-3.8.8-bin.tar.gz
sudo mv apache-maven-3.8.8 maven
```
lakukan konfigurasi dengan membuka fie:
```
sudo nano /etc/profile.d/maven.sh
```
tambahkan baris berikut ke dalam filenya dan `ctrl+o`, `enter` dan `ctrl+x` untuk simpan dan keluar.
```
export M2_HOME=/opt/maven
export PATH=${M2_HOME}/bin:${PATH}
```
terapkan konfigurasinya dengan command:
```
source /etc/profile.d/maven.sh
```
validasi maven dengan `mvn -v`.

2. jika maven sudah terinstall, buat direktori baru untuk menyimpan projek java, disini saya membuat folder berikut untuk meletakan file ProducerApp.java dan ConsumerApp.java.

sebagai konfigurasinya, buat file pom.xml dengan isi sebagai berikut:
```
<project xmlns="http://maven.apache.org/POM/4.0.0"
         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
    <modelVersion>4.0.0</modelVersion>
    <groupId>com.example</groupId>
    <artifactId>kafka-producer-consumer</artifactId>
    <version>1.0-SNAPSHOT</version>

    <properties>
        <maven.compiler.source>11</maven.compiler.source>
        <maven.compiler.target>11</maven.compiler.target>
    </properties>

    <dependencies>
        <dependency>
            <groupId>org.apache.kafka</groupId>
            <artifactId>kafka-clients</artifactId>
            <version>2.8.0</version>
        </dependency>

    </dependencies>

    <build>
        <plugins>
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                    <artifactId>maven-compiler-plugin</artifactId>
                    <version>3.8.1</version>
                    <configuration>
                        <source>${maven.compiler.source}</source>
                        <target>${maven.compiler.target}</target>
                    </configuration>
                </plugin>
                <plugin>
                    <groupId>org.apache.maven.plugins</groupId>
                    <artifactId>maven-shade-plugin</artifactId>
                    <version>3.2.4</version>
                    <executions>
                </executions>
            </plugin>
        </plugins>
    </build>
</project>
```
3. Untuk ProducerApp.java dan ConsumerApp.java buat masing masing di dalam direktori berikut:
```
kafka-producer-consumer/src/main/java/com/example
```
untuk ProcedurApp.java memiliki isi sebagai berikut yang mengatur message dengan key berurut, serta value berupa JSON sederhana yang isinya terdiri dari id, name dan email, message yang dikirimkan oleh producer dilakukan sebanyak 5 perulangan:
```
package com.example;

import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.apache.kafka.common.serialization.StringSerializer;

import java.util.Properties;
import java.util.concurrent.ExecutionException;

public class ProducerApp {

    public static void main(String[] args) throws ExecutionException, InterruptedException {
        Properties properties = new Properties();
        properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");
        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());

        KafkaProducer<String, String> producer = new KafkaProducer<>(properties);

        for (int i = 0; i < 5; i++) {
            String jsonMessage = "{"
                    + "\"id\":" + (i + 1) + ","
                    + "\"name\":\"ferdy " + (i + 1) + "\","
                    + "\"email\":\"ferdy" + (i + 1) + "@example.com\""
                    + "}";

            ProducerRecord<String, String> message = new ProducerRecord<>("java", Integer.toString(i), jsonMessage);
            producer.send(message).get();
        }

        producer.close();
    }
}
```
untuk ConsumerApp.java, digunakan untuk subscribe messagenya dan menampilkannya dengan format berisi:
```
package com.example;

import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.apache.kafka.clients.consumer.ConsumerRecords;
import org.apache.kafka.clients.consumer.KafkaConsumer;
import org.apache.kafka.common.serialization.StringDeserializer;

import java.time.Duration;
import java.util.Collections;
import java.util.Properties;
import java.util.List;

public class ConsumerApp {

    public static void main(String[] args) {
        Properties properties = new Properties();
        properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");
        properties.put(ConsumerConfig.GROUP_ID_CONFIG, "java");
        properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
        properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
        properties.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, "earliest");

        KafkaConsumer<String, String> consumer = new KafkaConsumer<>(properties);
        consumer.subscribe(List.of("java"));

        while (true) {
            ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(1));
            for (ConsumerRecord<String, String> record : records) {
                System.out.println("Message diterima: key: "+record.key() + " value: " +  record.value()+ " partisi: "+ record.partition()+ " offset: "+                                                record.offset())
            }
        }
    }
}
```
4. Setelah semuanya sudah dibuat, compile menggunakan maven sampai menghasilkan file jar dengan perintah:
```
mvn clean package
```
![image](https://github.com/ferdyansahalfariz/belajar-linux/assets/96871156/d1380b75-ebef-4207-b204-1e4d456a9e60)

hasil yang di dapat berupa file berikut yang ada dalam direktori target:
```
kafka-producer-consumer-1.0-SNAPSHOT.jar
```
5. Run masing-masing aplikasinya baik producer ataupun consumer dengan perintah masing-masing:
```
java -cp kafka-producer-consumer/target/kafka-producer-consumer-1.0-SNAPSHOT.jar com.example.ConsumerApp
```
```
java -cp kafka-producer-consumer/target/kafka-producer-consumer-1.0-SNAPSHOT.jar com.example.ProducerApp
```
6. Pengetesan dilakukan dengan running 2 aplikasi consumer dan 1 aplikasi producer. Dapat dilihat bahwa aplikasi berjalan normal dan message dapat terbagi partisinya sesuai dengan key. Pada sisi kiri adalah aplikasi Producer dan sisi kanan adalah 2 aplikasi Consumer:

![image](https://github.com/ferdyansahalfariz/belajar-linux/assets/96871156/be9d9569-4f50-4d3b-a2d6-d4d28d7311f2)

# 7 Juni 2024

Pada aplikasi sebelumnya, terdapat sedikit permasalahan dimana log level `DEBUG` selalu tampil pada aplikasi consumer yang membuatnya lebih sulit untuk membaca message yang masuk, karena hal tersebut saya tidak menerapkan loging dengan `log4j`, pada kesempatan kali ini saya berusaha memoerbaikinya dengan mengatur level log yang diperbolehkan untuk dicetak menjadi log `INFO` atau yang diatasnya dengan menambahkan konfigurasi pada file `log4j.properties` di direktori `kafka-producer-consumer/src/main/resources/` dengan isi sebagai berikut:

```
# Define the root logger with console appender
log4j.rootLogger=INFO, stdout

# Define the console appender
log4j.appender.stdout=org.apache.log4j.ConsoleAppender
log4j.appender.stdout.layout=org.apache.log4j.PatternLayout

# Define the pattern layout for the console appender
log4j.appender.stdout.layout.ConversionPattern=%d{yyyy-MM-dd HH:mm:ss} %-5p %c{1}:%L - %m%n
```

pada pom.xml juga ditambahkan dependency sebagai berikut:

```
        <dependency>
            <groupId>log4j</groupId>
            <artifactId>log4j</artifactId>
            <version>1.2.17</version>
        </dependency>
        <dependency>
            <groupId>org.slf4j</groupId>
            <artifactId>slf4j-api</artifactId>
            <version>1.7.36</version>
        </dependency>
        <dependency>
            <groupId>org.slf4j</groupId>
            <artifactId>slf4j-log4j12</artifactId>
            <version>1.7.36</version>
        </dependency>
```

# Membuat kafka admin client untuk hapus dan membuat topik baru

pada kesempatan kali ini setelah berhasil membuat producer dan consumer menggunakan java, sekarang saya akan membuat admin client yang dapat menghapus juga membuat topik baru menggunakan java. selain itu saya juga akan membuat ketiga service baik itu admin, producer dan consumer menggunakan systemd.

## Membuat file baru AdminApp.java

buat file java baru dengan isi berikut:
```
package com.example;

import org.apache.kafka.clients.admin.AdminClient;
import org.apache.kafka.clients.admin.CreateTopicsResult;
import org.apache.kafka.clients.admin.DeleteTopicsResult;
import org.apache.kafka.clients.admin.NewTopic;

import java.util.Collections;
import java.util.Properties;
import java.util.concurrent.ExecutionException;

public class AdminApp {
    public static void main(String[] args) {
        // Kafka broker address configuration
        Properties config = new Properties();
        config.put("bootstrap.servers", "localhost:9092");

        // Create AdminClient
        try (AdminClient adminClient = AdminClient.create(config)) {
            // Delete topic
            deleteTopic(adminClient, "notifications-new");
            // Recreate topic
            createTopic(adminClient, "notifications-new", 1, (short) 1);
        } catch (Exception e) {
            e.printStackTrace();
        }
    }

    private static void deleteTopic(AdminClient adminClient, String topicName) {
        DeleteTopicsResult deleteTopicsResult = adminClient.deleteTopics(Collections.singletonList(topicName));
        try {
            deleteTopicsResult.all().get();
            System.out.println("Topic " + topicName + " deleted successfully.");
        } catch (InterruptedException | ExecutionException e) {
            System.err.println("Failed to delete topic " + topicName);
            e.printStackTrace();
        }
    }

    private static void createTopic(AdminClient adminClient, String topicName, int numPartitions, short replicationFactor) {
        NewTopic newTopic = new NewTopic(topicName, numPartitions, replicationFactor);
        CreateTopicsResult createTopicsResult = adminClient.createTopics(Collections.singletonList(newTopic));
        try {
            createTopicsResult.all().get();
            System.out.println("Topic " + topicName + " created successfully.");
        } catch (InterruptedException | ExecutionException e) {
            System.err.println("Failed to create topic " + topicName);
            e.printStackTrace();
        }
    }

    private static void createTopic(AdminClient adminClient, String topicName, int numPartitions, short replicationFactor) {
        NewTopic newTopic = new NewTopic(topicName, numPartitions, replicationFactor);
        CreateTopicsResult createTopicsResult = adminClient.createTopics(Collections.singletonList(newTopic));
        try {
            createTopicsResult.all().get();
            System.out.println("Topic " + topicName + " created successfully.");
        } catch (InterruptedException | ExecutionException e) {
            System.err.println("Failed to create topic " + topicName);
            e.printStackTrace();
        }
    }
}
```
## Ubah versi kafka client yang ada di pom.xml dari 2.8.0 jadi 3.7.0
```
        <dependency>
            <groupId>org.apache.kafka</groupId>
            <artifactId>kafka-clients</artifactId>
            <version>3.7.0</version>
        </dependency>
```
## Compile kembali maven
Lakukan dengan perintah `mvn clean package` untuk compile filenya dalam direktori tempat menyimpan projek java.

## test run admin app
run AdminApp.java untuk mengecek apakah sudah jalan atau error berikut:
```
java -cp kafka-producer-consumer/target/kafka-producer-consumer-1.0-SNAPSHOT.jar com.example.AdminApp
```

![image](https://github.com/ferdyansahalfariz/belajar-linux/assets/96871156/a239ac78-f0f7-4296-b8c5-081216ef3e9f)

## Buat service baru di systemd
Setelah file berhasil tercompile sampai berbentuk jar. selanjutnya buat service baru pada `/etc/systemd/system/` yaitu berupa `consumer.service`, `producer.service` serta `admin.service` untuk menjalankan ketiga aplikasi tersebut. untuk isinya sebagai berikut:
```
[Unit]
Description=AdminApp Kafka Admin Client
After=network.target

[Service]
User=userA
ExecStart=/usr/bin/java -Dlog4j.configuration=file:/kafka-producer-consumer/src/main/resources/log4j.properties -cp /kafka-producer-consumer/target/kafka-producer-consumer-1.0-SNAPSHOT.jar com.example.AdminApp
Restart=no

[Install]
WantedBy=multi-user.target
```

`-Dlog4j.configuration=file:/kafka-producer-consumer/src/main/resources/log4j.properties` berguna untuk menerapkan konfigurasi yang akan dupakai dalam eksekusi programnya, kemudian untuk `Restart=no` diterapkan karena untuk aplikasi producer dan admin dibuat untuk langsung close setelah dirun, lain halnya dengan consumer yang dibuat `Restart=always` karena befungsi untuk subscribe message, bukan untuk publish ataupun merubah dan menambah topic baru.

## Jalankan Service
lakukan reload dan service dapat langsung dijalankan sebagai berikut:
```
systemctl daemon-reload
```
```
systemctl start (*nama service)
```
Pada service admin, berikut adalah hasil run nya yang menunjukan topic yang ingin dihapus sudah ditandai untuk dihapus dan setelahnya akan terhapus serta dibuatkan topik yang baru:

![image](https://github.com/ferdyansahalfariz/belajar-linux/assets/96871156/7f0ca269-888b-4166-abf3-c9c9e94cdbf5)

Untuk service Producer dapat dilihat contoh dari service producer yang berhasil di run, pada sisi kiri menunjukan service producer dijalankan 2 kali dan di sisi kanan dijalankan program consumer untuk menerima message yang dikirim dari producer tersebut.

![image](https://github.com/ferdyansahalfariz/belajar-linux/assets/96871156/e6cd3291-55fe-4fa3-ae64-8774233b14d3)

Status juga dapat di cek dengan 
```
systemctl status (admin/producer/consumer)
```

Untuk melihat Logs:
```
journalctl -u (admin/producer/consumer)
```

